# -*- coding: utf-8 -*-
# File Version: v2.5.1
# Project Version: v2.5.1
# Last Updated: 2025-07-04

import os
import json
import csv
import re
from typing import List, Dict, Set
from datetime import datetime
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from tqdm import tqdm
from dotenv import load_dotenv
from .utils import normalize_subject_name, get_year_from_user

def get_current_year() -> int:
    """ç¾åœ¨ã®å¹´åº¦ã‚’å–å¾—ã™ã‚‹"""
    return datetime.now().year

def get_csv_files(year: int) -> List[str]:
    """æŒ‡å®šã•ã‚ŒãŸå¹´åº¦ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ã™ã‚‹ï¼ˆcsvã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚å«ã‚€ï¼‰"""
    base_dir = os.path.join("src", "course_guide", str(year), "csv")
    if not os.path.exists(base_dir):
        raise FileNotFoundError(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_dir}")
    
    # csvã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å•ã„åˆã‚ã›
    subdirs = []
    for item in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item)
        if os.path.isdir(item_path):
            subdirs.append(item)
    
    csv_files = []
    
    if subdirs:
        print(f"è¦‹ã¤ã‹ã£ãŸcsvã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {', '.join(subdirs)}")
        while True:
            subdir_input = input("å‡¦ç†ã™ã‚‹csvã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆç©ºã®å ´åˆã¯å…¨ã¦å‡¦ç†ï¼‰: ").strip()
            if not subdir_input:
                # å…¨ã¦ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†
                # ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆcsvï¼‰ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                for file in os.listdir(base_dir):
                    if file.endswith('.csv'):
                        csv_files.append(os.path.join(base_dir, file))
                
                # å…¨ã¦ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                for subdir in subdirs:
                    subdir_path = os.path.join(base_dir, subdir)
                    if os.path.isdir(subdir_path):
                        for file in os.listdir(subdir_path):
                            if file.endswith('.csv'):
                                csv_files.append(os.path.join(subdir_path, file))
                break
            elif subdir_input in subdirs:
                # æŒ‡å®šã•ã‚ŒãŸã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿å‡¦ç†
                subdir_path = os.path.join(base_dir, subdir_input)
                if os.path.isdir(subdir_path):
                    for file in os.listdir(subdir_path):
                        if file.endswith('.csv'):
                            csv_files.append(os.path.join(subdir_path, file))
                break
            else:
                print(f"ç„¡åŠ¹ãªã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã™ã€‚æœ‰åŠ¹ãªé¸æŠè‚¢: {', '.join(subdirs)}")
    else:
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã„å ´åˆã¯ãƒ¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿å‡¦ç†
        for file in os.listdir(base_dir):
            if file.endswith('.csv'):
                csv_files.append(os.path.join(base_dir, file))
    
    if not csv_files:
        raise FileNotFoundError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_dir}")
    
    return csv_files

def get_db_connection(db_config: Dict[str, str]):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ã™ã‚‹"""
    # æ¥ç¶šæ–‡å­—åˆ—ã‚’ä½œæˆ
    connection_string = f"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['db']}"
    
    # ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ
    engine = create_engine(
        connection_string,
        connect_args={
            'options': '-c client_encoding=utf-8'
        }
    )
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    Session = sessionmaker(bind=engine)
    session = Session()
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆæ™‚ã«ä¸€åº¦ã ã‘æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¨­å®š
    session.execute(text("SET client_encoding TO 'utf-8'"))
    session.commit()
    
    return session

def clean_subject_name(name: str) -> str:
    """ç§‘ç›®åã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ï¼ˆ[éš”å¹´é–‹è¬›]ãªã©ã‚’å‰Šé™¤ï¼‰"""
    if not name:
        return name
    
    # [éš”å¹´é–‹è¬›]ã‚’å‰Šé™¤
    name = re.sub(r'\[éš”å¹´é–‹è¬›\]', '', name)
    
    # å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    name = name.strip()
    
    return name

def get_subject_name_id_from_db(session, name: str) -> int:
    """ç§‘ç›®åIDã‚’å–å¾—ã™ã‚‹"""
    try:
        # ç§‘ç›®åã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆ[éš”å¹´é–‹è¬›]ãªã©ã‚’å‰Šé™¤ï¼‰
        cleaned_name = clean_subject_name(name)
        
        # ç§‘ç›®åã‚’æ­£è¦åŒ–
        normalized_name = normalize_subject_name(cleaned_name)
        
        # ã¾ãšå®Œå…¨ä¸€è‡´ã§æ¤œç´¢
        query = text("""
            SELECT subject_name_id 
            FROM subject_name 
            WHERE name = :name
            ORDER BY subject_name_id
            LIMIT 1
        """)
        
        result = session.execute(
            query,
            {"name": normalized_name}
        ).first()
        
        if result:
            return result[0]
            
        # å®Œå…¨ä¸€è‡´ã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢
        query = text("""
            SELECT subject_name_id 
            FROM subject_name 
            WHERE name LIKE :name
            ORDER BY subject_name_id
            LIMIT 1
        """)
        
        result = session.execute(
            query,
            {"name": f"%{normalized_name}%"}
        ).first()
        
        if result:
            tqdm.write(f"è­¦å‘Š: ç§‘ç›®åã®éƒ¨åˆ†ä¸€è‡´ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {name} -> {normalized_name}")
            return result[0]
        
        # ãƒ­ãƒ¼ãƒæ•°å­—ã‚’é™¤å»ã—ã¦å†æ¤œç´¢
        name_without_roman = re.sub(r'[â… -â…©]', '', normalized_name)
        if name_without_roman != normalized_name:
            query = text("""
                SELECT subject_name_id 
                FROM subject_name 
                WHERE name LIKE :name
                ORDER BY subject_name_id
                LIMIT 1
            """)
            
            result = session.execute(
                query,
                {"name": f"%{name_without_roman}%"}
            ).first()
            
            if result:
                tqdm.write(f"è­¦å‘Š: ãƒ­ãƒ¼ãƒæ•°å­—ã‚’é™¤å»ã—ãŸç§‘ç›®åã®éƒ¨åˆ†ä¸€è‡´ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {name} -> {name_without_roman}")
                return result[0]
        
        tqdm.write(f"ã‚¨ãƒ©ãƒ¼: ç§‘ç›®åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {name} (æ­£è¦åŒ–å¾Œ: {normalized_name})")
        return None
            
    except Exception as e:
        tqdm.write(f"ã‚¨ãƒ©ãƒ¼: ç§‘ç›®åIDã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        session.rollback()
        return None

def get_faculty_id_from_db(session, faculty_name: str) -> int:
    """å­¦éƒ¨IDã‚’å–å¾—ã™ã‚‹"""
    try:
        query = text("""
            SELECT faculty_id 
            FROM faculty 
            WHERE faculty_name = :name
            ORDER BY faculty_id
            LIMIT 1
        """)
        
        result = session.execute(
            query,
            {"name": faculty_name}
        ).first()
        
        if result:
            return result[0]
        else:
            tqdm.write(f"ã‚¨ãƒ©ãƒ¼: å­¦éƒ¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {faculty_name}")
            return None
            
    except Exception as e:
        tqdm.write(f"ã‚¨ãƒ©ãƒ¼: å­¦éƒ¨IDã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        session.rollback()
        return None

def get_class_id_from_db(session, class_name: str) -> int:
    """ç§‘ç›®åŒºåˆ†IDã‚’å–å¾—ã™ã‚‹"""
    try:
        query = text("""
            SELECT class_id 
            FROM class 
            WHERE class_name = :name
            ORDER BY class_id
            LIMIT 1
        """)
        
        result = session.execute(
            query,
            {"name": class_name}
        ).first()
        
        if result:
            return result[0]
        else:
            tqdm.write(f"ã‚¨ãƒ©ãƒ¼: ç§‘ç›®åŒºåˆ†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {class_name}")
            return None
            
    except Exception as e:
        tqdm.write(f"ã‚¨ãƒ©ãƒ¼: ç§‘ç›®åŒºåˆ†IDã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        session.rollback()
        return None

def get_subclass_id_from_db(session, subclass_name: str) -> int:
    """ç§‘ç›®å°åŒºåˆ†IDã‚’å–å¾—ã™ã‚‹"""
    try:
        if not subclass_name:
            return None
            
        query = text("""
            SELECT subclass_id 
            FROM subclass 
            WHERE subclass_name = :name
            ORDER BY subclass_id
            LIMIT 1
        """)
        
        result = session.execute(
            query,
            {"name": subclass_name}
        ).first()
        
        if result:
            return result[0]
        else:
            tqdm.write(f"ã‚¨ãƒ©ãƒ¼: ç§‘ç›®å°åŒºåˆ†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {subclass_name}")
            return None
            
    except Exception as e:
        tqdm.write(f"ã‚¨ãƒ©ãƒ¼: ç§‘ç›®å°åŒºåˆ†IDã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        session.rollback()
        return None

def create_warning_csv(year: int, errors: List[Dict]) -> str:
    """ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’è©³ç´°ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜è¼‰ã™ã‚‹"""
    # è­¦å‘Šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    warning_dir = os.path.join("warning", str(year))
    os.makedirs(warning_dir, exist_ok=True)
    
    # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    current_time = datetime.now()
    filename = f"subject_{current_time.strftime('%Y%m%d_%H%M')}.csv"
    output_file = os.path.join(warning_dir, filename)
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’æ›¸ãè¾¼ã¿
    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        writer.writerow([
            'ãƒ•ã‚¡ã‚¤ãƒ«å',
            'è¡Œç•ªå·',
            'ç§‘ç›®å',
            'å­¦éƒ¨èª²ç¨‹',
            'å¹´åº¦',
            'ç§‘ç›®åŒºåˆ†',
            'ç§‘ç›®å°åŒºåˆ†',
            'å¿…é ˆåº¦',
            'ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—',
            'ã‚¨ãƒ©ãƒ¼è©³ç´°',
            'æ­£è¦åŒ–å¾Œç§‘ç›®å',
            'å‡¦ç†æ—¥æ™‚'
        ])
        
        # ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿
        for error in errors:
            writer.writerow([
                error.get('file_name', ''),
                error.get('row_number', ''),
                error.get('subject_name', ''),
                error.get('faculty_name', ''),
                error.get('year', ''),
                error.get('class_name', ''),
                error.get('subclass_name', ''),
                error.get('requirement_type', ''),
                error.get('error_type', ''),
                error.get('error_detail', ''),
                error.get('normalized_subject_name', ''),
                error.get('processed_at', '')
            ])
    
    return output_file

def extract_subject_info(csv_file: str, db_config: Dict[str, str], stats: Dict, errors: List[Dict]) -> List[Dict]:
    """CSVã‹ã‚‰ç§‘ç›®åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹"""
    subjects = []
    session = get_db_connection(db_config)
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f, delimiter='\t')
            rows = list(reader)
            stats['total_items'] += len(rows)
            
            for row_idx, row in enumerate(rows, start=2):  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ã„ã¦2ã‹ã‚‰é–‹å§‹
                try:
                    # ç§‘ç›®åã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦æ­£è¦åŒ–
                    subject_name = clean_subject_name(row['ç§‘ç›®å'])
                    normalized_subject_name = normalize_subject_name(subject_name)
                    
                    # å„IDã‚’å–å¾—
                    subject_name_id = get_subject_name_id_from_db(session, subject_name)
                    faculty_id = get_faculty_id_from_db(session, row['å­¦éƒ¨èª²ç¨‹'])
                    class_id = get_class_id_from_db(session, row['ç§‘ç›®åŒºåˆ†'])
                    subclass_id = get_subclass_id_from_db(session, row['ç§‘ç›®å°åŒºåˆ†']) if row['ç§‘ç›®å°åŒºåˆ†'] else None
                    
                    # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã¨ã‚¨ãƒ©ãƒ¼æƒ…å ±ã®åé›†
                    error_info = {
                        'file_name': os.path.basename(csv_file),
                        'row_number': row_idx,
                        'subject_name': row['ç§‘ç›®å'],
                        'faculty_name': row['å­¦éƒ¨èª²ç¨‹'],
                        'year': row['å¹´åº¦'],
                        'class_name': row['ç§‘ç›®åŒºåˆ†'],
                        'subclass_name': row['ç§‘ç›®å°åŒºåˆ†'],
                        'requirement_type': row['å¿…é ˆåº¦'],
                        'normalized_subject_name': normalized_subject_name,
                        'processed_at': datetime.now().isoformat()
                    }
                    
                    if subject_name_id is None:
                        error_info['error_type'] = 'ç§‘ç›®åIDæœªå–å¾—'
                        error_info['error_detail'] = f'ç§‘ç›®åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {subject_name} (æ­£è¦åŒ–å¾Œ: {normalized_subject_name})'
                        errors.append(error_info)
                        stats['error_items'] += 1
                        error_type = 'ç§‘ç›®åIDæœªå–å¾—'
                        if error_type not in stats['specific_errors']:
                            stats['specific_errors'][error_type] = 0
                        stats['specific_errors'][error_type] += 1
                        continue
                        
                    if faculty_id is None:
                        error_info['error_type'] = 'å­¦éƒ¨IDæœªå–å¾—'
                        error_info['error_detail'] = f'å­¦éƒ¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {row["å­¦éƒ¨èª²ç¨‹"]}'
                        errors.append(error_info)
                        stats['error_items'] += 1
                        error_type = 'å­¦éƒ¨IDæœªå–å¾—'
                        if error_type not in stats['specific_errors']:
                            stats['specific_errors'][error_type] = 0
                        stats['specific_errors'][error_type] += 1
                        continue
                        
                    if class_id is None:
                        error_info['error_type'] = 'ç§‘ç›®åŒºåˆ†IDæœªå–å¾—'
                        error_info['error_detail'] = f'ç§‘ç›®åŒºåˆ†ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {row["ç§‘ç›®åŒºåˆ†"]}'
                        errors.append(error_info)
                        stats['error_items'] += 1
                        error_type = 'ç§‘ç›®åŒºåˆ†IDæœªå–å¾—'
                        if error_type not in stats['specific_errors']:
                            stats['specific_errors'][error_type] = 0
                        stats['specific_errors'][error_type] += 1
                        continue
                        
                    subject_info = {
                        'subject_name_id': subject_name_id,
                        'faculty_id': faculty_id,
                        'curriculum_year': int(row['å¹´åº¦']),
                        'class_id': class_id,
                        'subclass_id': subclass_id,
                        'requirement_type': row['å¿…é ˆåº¦'] if row['å¿…é ˆåº¦'] else None,
                        'created_at': datetime.now().isoformat()
                    }
                    subjects.append(subject_info)
                    stats['valid_items'] += 1
                    
                except Exception as e:
                    error_info = {
                        'file_name': os.path.basename(csv_file),
                        'row_number': row_idx,
                        'subject_name': row.get('ç§‘ç›®å', ''),
                        'faculty_name': row.get('å­¦éƒ¨èª²ç¨‹', ''),
                        'year': row.get('å¹´åº¦', ''),
                        'class_name': row.get('ç§‘ç›®åŒºåˆ†', ''),
                        'subclass_name': row.get('ç§‘ç›®å°åŒºåˆ†', ''),
                        'requirement_type': row.get('å¿…é ˆåº¦', ''),
                        'normalized_subject_name': '',
                        'error_type': 'ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼',
                        'error_detail': str(e),
                        'processed_at': datetime.now().isoformat()
                    }
                    errors.append(error_info)
                    stats['error_items'] += 1
                    error_type = 'ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼'
                    if error_type not in stats['specific_errors']:
                        stats['specific_errors'][error_type] = 0
                    stats['specific_errors'][error_type] += 1
                    tqdm.write(f"ã‚¨ãƒ©ãƒ¼: è¡Œã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    continue
    finally:
        session.close()
    
    return subjects

def create_subject_json(subjects: List[Dict]) -> str:
    """ç§‘ç›®åŸºæœ¬æƒ…å ±ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹"""
    output_dir = os.path.join("updates", "subject", "add")
    os.makedirs(output_dir, exist_ok=True)
    
    # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    current_time = datetime.now()
    filename = f"subject_{current_time.strftime('%Y%m%d_%H%M')}.json"
    output_file = os.path.join(output_dir, filename)
    
    data = {
        "subjects": [{
            "subject_name_id": subject["subject_name_id"],
            "faculty_id": subject["faculty_id"],
            "curriculum_year": subject["curriculum_year"],
            "class_id": subject["class_id"],
            "subclass_id": subject["subclass_id"],
            "requirement_type": subject["requirement_type"],
            "created_at": subject["created_at"]
        } for subject in sorted(subjects, key=lambda x: (
            x["subject_name_id"],
            x["faculty_id"],
            x["curriculum_year"],
            x["class_id"],
            x["subclass_id"] if x["subclass_id"] is not None else 0
        ))]
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return output_file

def main(db_config: Dict[str, str]):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    try:
        # å¹´åº¦ã®å–å¾—
        year = get_year_from_user()
        
        # çµ±è¨ˆæƒ…å ±ã®åˆæœŸåŒ–
        stats = {
            'total_files': 0,
            'processed_files': 0,
            'total_items': 0,
            'valid_items': 0,
            'error_items': 0,
            'specific_errors': {}
        }
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã®åé›†ç”¨ãƒªã‚¹ãƒˆ
        errors = []
        
        # å‡¦ç†é–‹å§‹æ™‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        tqdm.write(f"\n{'='*60}")
        tqdm.write(f"ç§‘ç›®ãƒ‘ãƒ¼ã‚µãƒ¼ - å¯¾è±¡å¹´åº¦: {year}")
        tqdm.write(f"{'='*60}")
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
        csv_files = get_csv_files(year)
        stats['total_files'] = len(csv_files)
        tqdm.write(f"å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(csv_files)}")
        
        # ç§‘ç›®åŸºæœ¬æƒ…å ±ã®æŠ½å‡º
        all_subjects = []
        for csv_file in tqdm(csv_files, desc="CSVãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­", unit="file"):
            try:
                subjects = extract_subject_info(csv_file, db_config, stats, errors)
                all_subjects.extend(subjects)
                stats['processed_files'] += 1
                tqdm.write(f"ãƒ•ã‚¡ã‚¤ãƒ« {os.path.basename(csv_file)}: {len(subjects)}ä»¶ã®ç§‘ç›®ã‚’æŠ½å‡º")
            except Exception as e:
                tqdm.write(f"ãƒ•ã‚¡ã‚¤ãƒ« {os.path.basename(csv_file)} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                continue
        
        # é‡è¤‡ã‚’é™¤å»ï¼ˆsubject_name_id, faculty_id, curriculum_year, class_id, subclass_idã®çµ„ã¿åˆã‚ã›ã§ä¸€æ„ï¼‰
        unique_subjects = []
        seen_combinations = set()
        for subject in all_subjects:
            combination = (
                subject['subject_name_id'],
                subject['faculty_id'],
                subject['curriculum_year'],
                subject['class_id'],
                subject['subclass_id']
            )
            if combination not in seen_combinations:
                seen_combinations.add(combination)
                unique_subjects.append(subject)
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›
        if errors:
            warning_file = create_warning_csv(year, errors)
            tqdm.write(f"âš ï¸  ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã¾ã—ãŸ: {warning_file}")
        
        # æœ€çµ‚çµ±è¨ˆã®è¡¨ç¤º
        tqdm.write("\n" + "="*60)
        tqdm.write("å‡¦ç†å®Œäº† - çµ±è¨ˆæƒ…å ±")
        tqdm.write("="*60)
        tqdm.write(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_files']}")
        tqdm.write(f"å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['processed_files']}")
        tqdm.write(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {stats['total_items']}")
        tqdm.write(f"æ­£å¸¸ãƒ‡ãƒ¼ã‚¿æ•°: {stats['valid_items']}")
        tqdm.write(f"ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿æ•°: {stats['error_items']}")
        
        # ç‰¹å®šã‚¨ãƒ©ãƒ¼ã®è©³ç´°è¡¨ç¤º
        if stats['specific_errors']:
            tqdm.write("\nã‚¨ãƒ©ãƒ¼è©³ç´°:")
            for error_type, count in stats['specific_errors'].items():
                tqdm.write(f"  {error_type}: {count}ä»¶")
        
        tqdm.write("="*60)
        
        # çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
        tqdm.write(f"\n{'='*60}")
        tqdm.write("ğŸ“Š æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼")
        tqdm.write(f"{'='*60}")
        tqdm.write(f"âœ… æ­£å¸¸ãƒ‡ãƒ¼ã‚¿: {len(unique_subjects)}ä»¶")
        tqdm.write(f"âš ï¸  ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿: {stats['error_items']}ä»¶")
        tqdm.write(f"ğŸ“ˆ åˆè¨ˆ: {stats['total_items']}ä»¶")
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
        output_file = create_subject_json(unique_subjects)
        tqdm.write(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {output_file}")
        
    except Exception as e:
        tqdm.write(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        raise

if __name__ == "__main__":
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    load_dotenv()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼‰
    db_config = {
        'user': os.getenv('POSTGRES_USER', 'postgres'),
        'password': os.getenv('POSTGRES_PASSWORD', 'postgres'),
        'host': os.getenv('POSTGRES_HOST', 'localhost'),
        'port': os.getenv('POSTGRES_PORT', '5432'),
        'db': os.getenv('POSTGRES_DB', 'syllabus_db')
    }
    
    main(db_config) 