# -*- coding: utf-8 -*-
# File Version: v3.0.0
# Project Version: v3.0.0
# Last Updated: 2025/6/23
# Cursorã¯versionã‚’ã„ã˜ã‚‹ãª

import os
import json
import sys
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import re
from tqdm import tqdm
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
import unicodedata
import csv

# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# utils.pyã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
	from utils import normalize_subject_name, process_session_data, is_regular_session_list
except ImportError:
	# utils.pyãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
	def normalize_subject_name(text: str) -> str:
		"""æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–ã™ã‚‹é–¢æ•°"""
		return unicodedata.normalize('NFKC', text)
	
	def process_session_data(session_text: str) -> Tuple[bool, int, str, Optional[str]]:
		"""ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
		return False, 0, "", None
	
	def is_regular_session_list(schedule_data: list) -> bool:
		"""ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
		return False

def get_db_connection():
	"""ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ã™ã‚‹"""
	# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰æ¥ç¶šæƒ…å ±ã‚’å–å¾—
	user = os.getenv('POSTGRES_USER', 'postgres')
	password = os.getenv('POSTGRES_PASSWORD', 'postgres')
	host = os.getenv('POSTGRES_HOST', 'localhost')
	port = os.getenv('POSTGRES_PORT', '5432')
	db = os.getenv('POSTGRES_DB', 'syllabus_db')

	# æ¥ç¶šæ–‡å­—åˆ—ã‚’ä½œæˆ
	connection_string = f"postgresql://{user}:{password}@{host}:{port}/{db}"
	
	# ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ
	engine = create_engine(
		connection_string,
		connect_args={
			'options': '-c client_encoding=utf-8'
		}
	)
	
	# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
	Session = sessionmaker(bind=engine)
	session = Session()
	
	# ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå¾Œã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¨­å®š
	session.execute(text("SET client_encoding TO 'utf-8'"))
	session.commit()
	
	return session

def get_syllabus_master_id_from_db(session, syllabus_code: str, syllabus_year: int) -> Optional[int]:
	"""ã‚·ãƒ©ãƒã‚¹ãƒã‚¹ã‚¿ãƒ¼ã®IDã‚’å–å¾—ã™ã‚‹"""
	try:
		# ã‚·ãƒ©ãƒã‚¹ãƒã‚¹ã‚¿ãƒ¼ã®IDã‚’æ¤œç´¢
		query = text("""
			SELECT syllabus_id 
			FROM syllabus_master 
			WHERE syllabus_code = :code 
			AND syllabus_year = :year
		""")
		
		result = session.execute(
			query,
			{"code": syllabus_code, "year": syllabus_year}
		).first()
		
		if result and result[0] is not None:
			syllabus_id = result[0]
			# æ•´æ•°å‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
			if isinstance(syllabus_id, int) and syllabus_id > 0:
				return syllabus_id
			else:
				print(f"è­¦å‘Š: ç„¡åŠ¹ãªsyllabus_idãŒè¿”ã•ã‚Œã¾ã—ãŸ: {syllabus_id} (å‹: {type(syllabus_id)})")
				return None
		return None
	except Exception as e:
		print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {syllabus_code} ({syllabus_year}) - {str(e)}")
		session.rollback()
		return None

def get_current_year() -> int:
	"""ç¾åœ¨ã®å¹´ã‚’å–å¾—ã™ã‚‹"""
	return datetime.now().year

def get_year_from_user() -> int:
	"""ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å¹´ã‚’å…¥åŠ›ã—ã¦ã‚‚ã‚‰ã†"""
	while True:
		try:
			year = input("å¹´ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆç©ºã®å ´åˆã¯ç¾åœ¨ã®å¹´ï¼‰: ").strip()
			if not year:
				return get_current_year()
			year = int(year)
			if 2000 <= year <= 2100:  # å¦¥å½“ãªå¹´ã®ç¯„å›²ã‚’ãƒã‚§ãƒƒã‚¯
				return year
			print("2000å¹´ã‹ã‚‰2100å¹´ã®é–“ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
		except ValueError:
			print("æ­£ã—ã„æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

def parse_lecture_sessions_from_schedule(schedule_data: List[Dict]) -> List[Dict]:
	"""ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã¿ã‚’è§£æã—ã¦æ­£è¦åŒ–ã™ã‚‹"""
	import re  # é–¢æ•°å†…ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
	
	lecture_sessions = []  # é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã¿
	
	if not schedule_data:
		return lecture_sessions
	
	# ãƒªã‚¹ãƒˆå…¨ä½“ãŒæ­£è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š
	if not is_regular_session_list(schedule_data):
		return lecture_sessions
	
	for session_data in schedule_data:
		if not isinstance(session_data, dict):
			continue
		
		# ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—: "1å›ç›®" â†’ 1, "2å›ç›®" â†’ 2ãªã©
		session = session_data.get("session", "")
		if not session:
			continue
		
		# ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
		is_regular, session_number, _, lecture_format = process_session_data(session)
		
		# ä¸è¦å‰‡ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
		if not is_regular:
			continue
		
		# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç•ªå·ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
		if not isinstance(session_number, int) or session_number <= 0:
			print(f"è­¦å‘Š: ç„¡åŠ¹ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ç•ªå·ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {session_number} (å‹: {type(session_number)})")
			continue
		
		# ç•°å¸¸ã«å¤§ããªã‚»ãƒƒã‚·ãƒ§ãƒ³ç•ªå·ã®ãƒã‚§ãƒƒã‚¯ï¼ˆé€šå¸¸ã®è¬›ç¾©ã¯100å›ã‚’è¶…ãˆã‚‹ã“ã¨ã¯ãªã„ï¼‰
		if session_number > 100:
			print(f"è­¦å‘Š: ç•°å¸¸ã«å¤§ããªã‚»ãƒƒã‚·ãƒ§ãƒ³ç•ªå·ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {session_number} - ã“ã®å€¤ã¯æ­£ã—ã„ã§ã™ã‹ï¼Ÿ")
			# ç•°å¸¸ãªå€¤ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
			continue
		
		# å†…å®¹ã‚’å–å¾—
		contents = session_data.get("content", "")
		
		lecture_sessions.append({
			'syllabus_id': None,  # å¾Œã§è¨­å®š
			'session_number': session_number,
			'contents': contents if contents else None,
			'other_info': None,
			'lecture_format': lecture_format
		})
	
	# é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ã‚»ãƒƒãƒˆ
	seen_sessions = set()
	unique_sessions = []
	for session_data in lecture_sessions:
		if 'session_number' in session_data:
			session_number = session_data['session_number']
			if session_number not in seen_sessions:
				unique_sessions.append(session_data)
				seen_sessions.add(session_number)
	
	return unique_sessions

def get_json_files(year: int) -> List[str]:
	"""æŒ‡å®šã•ã‚ŒãŸå¹´ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
	json_dir = os.path.join("src", "syllabus", str(year), "json")
	json_files = []
	
	if os.path.exists(json_dir):
		for file in os.listdir(json_dir):
			if file.endswith('.json'):
				json_files.append(os.path.join(json_dir, file))
	
	return json_files

def extract_lecture_session_from_single_json(json_data: Dict, session, year: int, json_file: str) -> tuple[List[Dict], List[str]]:
	"""å˜ä¸€ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æŠ½å‡º"""
	lecture_sessions = []
	errors = []
	
	try:
		# JSONãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç§‘ç›®ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
		syllabus_code = json_data.get('ç§‘ç›®ã‚³ãƒ¼ãƒ‰')
		syllabus_year = year
		
		if not syllabus_code:
			errors.append(f"ç§‘ç›®ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_file}")
			return lecture_sessions, errors
		
		# ã‚·ãƒ©ãƒã‚¹ãƒã‚¹ã‚¿ãƒ¼ã®IDã‚’å–å¾—
		syllabus_master_id = get_syllabus_master_id_from_db(session, syllabus_code, syllabus_year)
		
		if not syllabus_master_id:
			errors.append(f"ã‚·ãƒ©ãƒã‚¹ãƒã‚¹ã‚¿ãƒ¼IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {syllabus_code} ({syllabus_year})")
			return lecture_sessions, errors
		
		# syllabus_master_idã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
		if not isinstance(syllabus_master_id, int) or syllabus_master_id <= 0:
			errors.append(f"ç„¡åŠ¹ãªã‚·ãƒ©ãƒã‚¹ãƒã‚¹ã‚¿ãƒ¼ID: {syllabus_master_id} (å‹: {type(syllabus_master_id)}) - {syllabus_code} ({syllabus_year})")
			return lecture_sessions, errors
		
		# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
		schedule_data = json_data.get('è¬›ç¾©è¨ˆç”»', {}).get('å†…å®¹', {}).get('schedule', [])
		
		# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è§£æ
		parsed_sessions = parse_lecture_sessions_from_schedule(schedule_data)
		
		# ã‚·ãƒ©ãƒã‚¹ãƒã‚¹ã‚¿ãƒ¼IDã‚’è¿½åŠ 
		for session_data in parsed_sessions:
			session_data['syllabus_id'] = syllabus_master_id
			lecture_sessions.append(session_data)
		
	except Exception as e:
		error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
		if 'syllabus_code' in locals():
			error_msg = f"ç§‘ç›®ã‚³ãƒ¼ãƒ‰ {syllabus_code}: {error_msg}"
		print(f"        EXTRACT ERROR: {error_msg}")
		errors.append(error_msg)
	
	return lecture_sessions, errors

def process_lecture_session_json(json_file: str, session, year: int) -> tuple[List[Dict], List[str]]:
	"""JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æŠ½å‡º"""
	all_lecture_sessions = []
	all_errors = []
	
	try:
		with open(json_file, 'r', encoding='utf-8') as f:
			json_data = json.load(f)
		
		lecture_sessions, errors = extract_lecture_session_from_single_json(json_data, session, year, json_file)
		
		all_lecture_sessions.extend(lecture_sessions)
		all_errors.extend(errors)
		
	except Exception as e:
		all_errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {json_file}: {str(e)}")
	
	return all_lecture_sessions, all_errors

def create_lecture_session_json(lecture_sessions: List[Dict]) -> str:
	"""è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
	output_dir = os.path.join("updates", "lecture_session", "add")
	os.makedirs(output_dir, exist_ok=True)
	
	timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
	filename = f"lecture_session_{timestamp}.json"
	filepath = os.path.join(output_dir, filename)
	
	print(f"  JSONãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ä¸­: {filename}")
	print(f"  ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(lecture_sessions):,}ä»¶")
	
	# ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’ç¢ºèª
	data_size = len(json.dumps(lecture_sessions, ensure_ascii=False))
	print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {data_size:,} ãƒã‚¤ãƒˆ ({data_size/1024/1024:.2f} MB)")
	
	try:
		# å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯åˆ†å‰²å‡¦ç†
		if len(lecture_sessions) > 100000:  # 10ä¸‡ä»¶ä»¥ä¸Š
			print(f"  å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚åˆ†å‰²å‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
			chunk_size = 50000  # 5ä¸‡ä»¶ãšã¤åˆ†å‰²
			chunks = [lecture_sessions[i:i + chunk_size] for i in range(0, len(lecture_sessions), chunk_size)]
			
			with open(filepath, 'w', encoding='utf-8') as f:
				f.write('[\n')
				for chunk_idx, chunk in enumerate(chunks):
					print(f"    ãƒãƒ£ãƒ³ã‚¯ {chunk_idx + 1}/{len(chunks)} ã‚’å‡¦ç†ä¸­...")
					for i, session in enumerate(chunk):
						if chunk_idx > 0 or i > 0:
							f.write(',\n')
						json.dump(session, f, ensure_ascii=False, indent=2)
				f.write('\n]')
		else:
			# é€šå¸¸ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›¸ãè¾¼ã¿
			print(f"  ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›¸ãè¾¼ã¿ã‚’å®Ÿè¡Œä¸­...")
			with open(filepath, 'w', encoding='utf-8') as f:
				f.write('[\n')
				for i, session in tqdm(enumerate(lecture_sessions), total=len(lecture_sessions), desc="  ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›¸ãè¾¼ã¿"):
					if i > 0:
						f.write(',\n')
					json.dump(session, f, ensure_ascii=False, indent=2)
				f.write('\n]')
		
		print(f"  æ›¸ãè¾¼ã¿å®Œäº†: {filepath}")
	except Exception as e:
		print(f"  æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
		raise
	
	return filepath

def create_error_csv(all_errors: List[str], final_session_errors: List[str], year: int) -> str:
	"""ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
	output_dir = os.path.join("warning", str(year))
	os.makedirs(output_dir, exist_ok=True)
	
	timestamp = datetime.now().strftime("%Y%m%d_%H%M")
	filename = f"lecture_session_{timestamp}.csv"
	filepath = os.path.join(output_dir, filename)
	
	print(f"  CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ä¸­: {filename}")
	with open(filepath, 'w', encoding='utf-8', newline='') as f:
		writer = csv.writer(f)
		writer.writerow(['ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—', 'ã‚¨ãƒ©ãƒ¼å†…å®¹'])
		
		for error in all_errors:
			writer.writerow(['å‡¦ç†ã‚¨ãƒ©ãƒ¼', error])
		
		for error in final_session_errors:
			writer.writerow(['æœ€çµ‚ã‚¨ãƒ©ãƒ¼', error])
	
	return filepath

def main():
	"""ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
	print("é€šå¸¸è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±æŠ½å‡ºå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
	
	# å¹´ã‚’å–å¾—
	year = get_year_from_user()
	
	# JSONãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
	json_files = get_json_files(year)
	if not json_files:
		print(f"{year}å¹´ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
		return
	
	# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
	try:
		session = get_db_connection()
	except Exception as e:
		print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
		return
	
	# çµ±è¨ˆæƒ…å ±ã®åˆæœŸåŒ–
	stats = {
		'total_files': len(json_files),
		'processed_files': 0,
		'total_items': 0,
		'valid_items': 0,
		'error_items': 0,
		'specific_errors': {}
	}
	
	# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™
	timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
	
	# é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«
	lecture_session_dir = os.path.join("updates", "lecture_session", "add")
	os.makedirs(lecture_session_dir, exist_ok=True)
	lecture_session_file = os.path.join(lecture_session_dir, f"lecture_session_{timestamp}.json")
	
	# ã‚¨ãƒ©ãƒ¼æƒ…å ±ç”¨ãƒ•ã‚¡ã‚¤ãƒ«
	error_dir = os.path.join("warning", str(year))
	os.makedirs(error_dir, exist_ok=True)
	error_file = os.path.join(error_dir, f"lecture_session_{timestamp}.csv")
	
	# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦æ›¸ãè¾¼ã¿é–‹å§‹
	lecture_session_count = 0
	all_errors = []
	
	# é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
	lecture_f = open(lecture_session_file, 'w', encoding='utf-8')
	lecture_f.write('[\n')
	lecture_first = True
	
	try:
		# å‡¦ç†é–‹å§‹æ™‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
		tqdm.write(f"\n{'='*60}")
		tqdm.write(f"é€šå¸¸è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±æŠ½å‡ºå‡¦ç† - å¯¾è±¡å¹´åº¦: {year}")
		tqdm.write(f"{'='*60}")
		
		for i, json_file in enumerate(tqdm(json_files, desc="JSONãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­", unit="file")):
			try:
				with open(json_file, 'r', encoding='utf-8') as f:
					json_data = json.load(f)
				
				lecture_sessions, errors = extract_lecture_session_from_single_json(json_data, session, year, json_file)
				
				# çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
				stats['processed_files'] += 1
				stats['total_items'] += len(lecture_sessions)
				stats['valid_items'] += len(lecture_sessions)
				stats['error_items'] += len(errors)
				
				# é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ›¸ãè¾¼ã¿
				for session_data in lecture_sessions:
					if not lecture_first:
						lecture_f.write(',\n')
					json.dump(session_data, lecture_f, ensure_ascii=False, indent=2)
					lecture_first = False
					lecture_session_count += 1
				
				all_errors.extend(errors)
				
			except Exception as e:
				error_msg = f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {json_file}: {str(e)}"
				tqdm.write(f"ã‚¨ãƒ©ãƒ¼: {error_msg}")
				all_errors.append(error_msg)
				stats['error_items'] += 1
		
		# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
		lecture_f.write('\n]')
		lecture_f.close()
		
	except Exception as e:
		# ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
		try:
			lecture_f.close()
		except:
			pass
		raise e
	
	# æœ€çµ‚çµ±è¨ˆã®è¡¨ç¤º
	tqdm.write("\n" + "="*60)
	tqdm.write("å‡¦ç†å®Œäº† - çµ±è¨ˆæƒ…å ±")
	tqdm.write("="*60)
	tqdm.write(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_files']}")
	tqdm.write(f"å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['processed_files']}")
	tqdm.write(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {stats['total_items']}")
	tqdm.write(f"æ­£å¸¸ãƒ‡ãƒ¼ã‚¿æ•°: {stats['valid_items']}")
	tqdm.write(f"ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿æ•°: {stats['error_items']}")
	tqdm.write("="*60)
	
	# çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
	tqdm.write(f"\n{'='*60}")
	tqdm.write("ğŸ“Š æŠ½å‡ºçµæœã‚µãƒãƒªãƒ¼")
	tqdm.write(f"{'='*60}")
	tqdm.write(f"âœ… é€šå¸¸ã‚»ãƒƒã‚·ãƒ§ãƒ³: {lecture_session_count:,}ä»¶")
	tqdm.write(f"âš ï¸  ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿: {len(all_errors)}ä»¶")
	tqdm.write(f"ğŸ“ˆ åˆè¨ˆ: {lecture_session_count:,}ä»¶")
	
	# çµæœã‚’è¡¨ç¤º
	final_session_errors = []
	
	if lecture_session_count > 0:
		tqdm.write(f"é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {lecture_session_file}")
	else:
		final_session_errors.append("é€šå¸¸ã®è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
	
	# ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ä¿å­˜
	if all_errors or final_session_errors:
		with open(error_file, 'w', encoding='utf-8', newline='') as f:
			writer = csv.writer(f)
			writer.writerow(['ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—', 'ã‚¨ãƒ©ãƒ¼å†…å®¹'])
			
			for error in all_errors:
				writer.writerow(['å‡¦ç†ã‚¨ãƒ©ãƒ¼', error])
			
			for error in final_session_errors:
				writer.writerow(['æœ€çµ‚ã‚¨ãƒ©ãƒ¼', error])
		
		tqdm.write(f"ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {error_file}")
	
	# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‰ã˜ã‚‹
	session.close()
	
	tqdm.write("é€šå¸¸è¬›ç¾©ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±æŠ½å‡ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")

if __name__ == "__main__":
	main() 